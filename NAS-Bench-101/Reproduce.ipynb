{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of  `epsilon` metric\n",
    "\n",
    "If you wish to reproduce the results presented in our paper from scratch, feel free to use the below code.\n",
    "In this notebook, we provide the codes to reproduce the results for NAS-Bench-101 sarch space, CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy import stats\n",
    "from tqdm import trange\n",
    "from dotmap import DotMap\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import nasspace\n",
    "from datasets import data\n",
    "from epsinas_utils import prepare_seed, compute_epsinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "data_loc = './datasets/cifardata'\n",
    "batch_size = 256\n",
    "repeat = 1\n",
    "GPU = '0'\n",
    "augtype = 'none'\n",
    "trainval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments required for NAS-Bench-101 search space initialisation\n",
    "args = DotMap()\n",
    "\n",
    "args.api_loc = './nasbench_only108.tfrecord'\n",
    "args.nasspace = 'nasbench101'\n",
    "args.dataset = dataset\n",
    "args.stem_out_channels = 128\n",
    "args.num_stacks = 3\n",
    "args.num_modules_per_stack = 3\n",
    "args.num_labels = 1\n",
    "\n",
    "savedataset = dataset\n",
    "dataset = 'fake' if 'fake' in savedataset else savedataset\n",
    "savedataset = savedataset.replace('fake', '')\n",
    "if savedataset == 'cifar10':\n",
    "    savedataset = savedataset + '-valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the search space (it takes some time)\n",
    "searchspace = nasspace.get_search_space(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'valid' in savedataset:\n",
    "    savedataset = savedataset.replace('-valid', '')\n",
    "    \n",
    "if args.dataset == 'cifar10':\n",
    "    acc_type = 'ori-test'\n",
    "    val_acc_type = 'x-valid'\n",
    "else:\n",
    "    acc_type = 'x-test'\n",
    "    val_acc_type = 'x-valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Randomly select n_samples architectures\n",
    "prepare_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "train_loader = data.get_data(dataset, data_loc, trainval, batch_size, augtype, repeat, args)\n",
    "\n",
    "# Pick up a batch\n",
    "data_iterator = iter(train_loader)\n",
    "x, _= next(data_iterator)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = f'../epsinas-release-data/NAS-Bench-101/evaluation/{dataset.upper()}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "datafile_name = f'{save_dir}/data_NAS-Bench-101_{dataset.upper()}_test'\n",
    "\n",
    "if os.path.exists(datafile_name):\n",
    "    # Load precomputed results\n",
    "    datafile = open(datafile_name,'rb')\n",
    "    input_data = pkl.load(datafile)\n",
    "    scores = input_data[\"scores\"]\n",
    "    test_accs_mean = input_data[\"test_accs_mean\"]\n",
    "    test_accs_min = input_data[\"test_accs_min\"]\n",
    "    test_accs_max = input_data[\"test_accs_max\"]\n",
    "    val_accs_mean = input_data[\"val_accs_mean\"]\n",
    "    val_accs_min = input_data[\"val_accs_min\"]\n",
    "    val_accs_max = input_data[\"val_accs_max\"]\n",
    "    nparams = input_data[\"nparams\"]\n",
    "else:\n",
    "    weights = [1e-4, 10]\n",
    "    test_accs_mean = []\n",
    "    test_accs_min = []\n",
    "    test_accs_max = []\n",
    "    val_accs_mean = []\n",
    "    val_accs_min = []\n",
    "    val_accs_max = []\n",
    "    nparams = []\n",
    "    scores = []\n",
    "    times = []\n",
    "    \n",
    "    for i in trange(len(searchspace)):\n",
    "        start = time.time()\n",
    "        uid = searchspace[i]\n",
    "        network = searchspace.get_network(uid)\n",
    "        network = network.to(device)\n",
    "        score = compute_epsinas(x, network, weights)\n",
    "        scores.append(score)\n",
    "        nparams.append(sum(p.numel() for p in network.parameters()))\n",
    "        test_accs_mean.append(searchspace.get_final_accuracy(uid, acc_type, False)[0])\n",
    "        test_accs_min.append(searchspace.get_final_accuracy(uid, acc_type, False)[1])\n",
    "        test_accs_max.append(searchspace.get_final_accuracy(uid, acc_type, False)[2])\n",
    "        val_accs_mean.append(searchspace.get_final_accuracy(uid, val_acc_type, False)[0])\n",
    "        val_accs_min.append(searchspace.get_final_accuracy(uid, val_acc_type, False)[1])\n",
    "        val_accs_max.append(searchspace.get_final_accuracy(uid, val_acc_type, False)[2])\n",
    "        times.append(time.time()-start)\n",
    "\n",
    "    # Save your results\n",
    "    save_dic = {}\n",
    "    save_dic[\"scores\"] = scores\n",
    "    save_dic[\"test_accs_mean\"] = test_accs_mean\n",
    "    save_dic[\"test_accs_min\"] = test_accs_min\n",
    "    save_dic[\"test_accs_max\"] = test_accs_max\n",
    "    save_dic[\"val_accs_mean\"] = val_accs_mean\n",
    "    save_dic[\"val_accs_min\"] = val_accs_min\n",
    "    save_dic[\"val_accs_max\"] = val_accs_max\n",
    "    save_dic[\"nparams\"] = nparams\n",
    "\n",
    "    pkl.dump(save_dic, open(datafile_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
